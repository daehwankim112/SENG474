{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b44394-c2fb-4724-affa-cf07d8d8c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Part 1: Data Loading and Preprocessing\n",
    "########################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import neighbors\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2cc3a72-4933-4bd6-97f7-4289e84f05bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Example rows:\n",
      "                       id  danceability    energy       key  loudness  \\\n",
      "0  7lmeHLHBe4nmXzuXc0HDjk     -0.239643  1.545439  0.504262  0.855004   \n",
      "1  1wsRitfRRtWyEapl0q22o8      0.448997  1.470214  1.632828  0.794662   \n",
      "2  1hR0fIFK2qRG3f3RF70pb7     -1.067078  1.516782  0.504262  0.850871   \n",
      "3  2lbASgTSoDO7MTuLAXlTW0     -0.399791  1.506035  1.632828  0.783751   \n",
      "4  1MQTmpYOZ6fcMQc56Hdo7T     -0.474528  1.369913 -0.906446  0.635127   \n",
      "\n",
      "   speechiness  acousticness  instrumentalness  liveness   valence  ...  \\\n",
      "0    -0.084450     -1.018675         -0.663029  0.731281  0.184434  ...   \n",
      "1     0.998881     -1.054604         -0.662862 -0.286777  0.132294  ...   \n",
      "2     3.770628     -1.026024         -0.663054 -0.453920 -0.310892  ...   \n",
      "3     1.459273     -0.646043         -0.663049 -0.458985  0.448856  ...   \n",
      "4    -0.108879     -1.085308         -0.369701 -0.672220  0.318507  ...   \n",
      "\n",
      "   loc_pca_0  loc_pca_1  loc_pca_2  loc_pca_3  loc_pca_4  loc_pca_5  \\\n",
      "0  24.203403  -0.158920   0.247126   0.789665  -0.060023  -0.640468   \n",
      "1  28.493807   0.228536   0.646449   1.706311  -0.004733  -1.077771   \n",
      "2   4.036218  -0.282505   0.266417   0.224058  -0.022911  -1.097135   \n",
      "3   0.141121  -0.180057   0.039945  -0.117471   0.191789  -0.015862   \n",
      "4  11.897067  -0.646398   0.500255  -0.252342   0.111723  -0.587308   \n",
      "\n",
      "   loc_pca_6  loc_pca_7  loc_pca_8  loc_pca_9  \n",
      "0   1.330385  -0.857548  -0.423787   0.039703  \n",
      "1   0.702044  -1.451287   0.963210   0.337379  \n",
      "2  -0.075220  -0.147339   0.320747  -0.147518  \n",
      "3   0.012023  -0.025625   0.022630  -0.076836  \n",
      "4   0.765197  -0.737422  -0.186457  -0.062984  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data from new_features.csv\n",
    "df = pd.read_csv(\"../data/new_features.csv\")\n",
    "print(\"Data loaded. Example rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99b898ce-a017-44f6-9f95-3a892a15cf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interaction matrix shape: (134712, 10)\n"
     ]
    }
   ],
   "source": [
    "# Extract the playlist location features (PCA-reduced), e.g., loc_pca_0 ... loc_pca_9\n",
    "loc_pca_cols = [col for col in df.columns if col.startswith(\"loc_pca_\")]\n",
    "interaction_matrix = df[loc_pca_cols].values\n",
    "print(\"\\nInteraction matrix shape:\", interaction_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87feb08d-6d99-48e0-b0a2-90b2acf66b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF latent factors shape: (134712, 10)\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Part 2: Collaborative Filtering (CF) via SVD\n",
    "########################################\n",
    "# Apply Truncated SVD to the interaction matrix to obtain CF latent factors\n",
    "n_components = min(50, interaction_matrix.shape[1])\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "cf_latent = svd.fit_transform(interaction_matrix)\n",
    "print(\"CF latent factors shape:\", cf_latent.shape)\n",
    "\n",
    "# Map each track ID to its CF latent vector\n",
    "all_track_ids = df[\"id\"].values\n",
    "track_latent = {track_id: cf_latent[i] for i, track_id in enumerate(all_track_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39be6658-3c0c-4b1e-bd9e-d18dcf36751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation function using dot product similarity (Pure CF)\n",
    "def recommend_tracks_dot_with_scores(target_track, track_latent, top_n=10):\n",
    "    if target_track not in track_latent:\n",
    "        print(f\"Track {target_track} not found.\")\n",
    "        return []\n",
    "    target_vector = track_latent[target_track]\n",
    "    all_track_ids_list = list(track_latent.keys())\n",
    "    all_vectors = np.array(list(track_latent.values()))\n",
    "    similarities = np.dot(all_vectors, target_vector)\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    recommendations = [(all_track_ids_list[i], similarities[i])\n",
    "                       for i in sorted_indices if all_track_ids_list[i] != target_track]\n",
    "    return recommendations[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b676a737-e1cd-4cf9-8154-6320d9917d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content features shape: (134712, 4)\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Part 3: Content-Based Feature Extraction\n",
    "########################################\n",
    "# Define audio feature columns; ensure popularity is present\n",
    "audio_cols = [\"danceability\", \"energy\", \"valence\", \"tempo\"]\n",
    "#if \"popularity\" not in df.columns:\n",
    "#    if \"occurrence_count\" in df.columns:\n",
    "#        df[\"popularity\"] = df[\"occurrence_count\"]\n",
    "#    else:\n",
    "#        df[\"popularity\"] = 1 # np.random.randint(100, 1000, size=len(df)) # Why? -David\n",
    "#content_cols = audio_cols + [\"popularity\"]\n",
    "\n",
    "# Standardize the content features\n",
    "scaler = StandardScaler()\n",
    "# content_scaled = scaler.fit_transform(df[content_cols].values)\n",
    "content_scaled = scaler.fit_transform(df[audio_cols].values)\n",
    "print(\"Content features shape:\", content_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca25dc92-8cc8-400d-886c-c09ff3c98e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid vector shape: (134712, 14)\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Part 4: Hybrid Vector Construction\n",
    "########################################\n",
    "# Hybrid vector = [CF latent vector, Content features]\n",
    "hybrid_vectors = np.concatenate([cf_latent, content_scaled], axis=1) # cf_latent.shape = (134712, 10)\n",
    "print(\"Hybrid vector shape:\", hybrid_vectors.shape)\n",
    "# Build a discionary based on hybrid_vectors by id\n",
    "hybrid_dict = {df.iloc[i][\"id\"]: hybrid_vectors[i] for i in range(len(df))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58b10235-5a3d-4497-87ea-774ca4f52a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Part 5: Recommendation Function for Hybrid Model\n",
    "########################################\n",
    "def recommend_hybrid(target_track, hybrid_dict, top_n=10):\n",
    "    if target_track not in hybrid_dict:\n",
    "        print(f\"Track {target_track} not found.\")\n",
    "        return []\n",
    "    target_vector = hybrid_dict[target_track]\n",
    "    all_ids = list(hybrid_dict.keys())\n",
    "    all_vectors = np.array(list(hybrid_dict.values()))\n",
    "    similarities = np.dot(all_vectors, target_vector) # Interesting. This works? - David\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    recommendations = [(all_ids[i], similarities[i])\n",
    "                       for i in sorted_indices if all_ids[i] != target_track]\n",
    "    return recommendations[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2f735d0-9fc2-462d-a6e3-7545edf5409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Part 6: Recommendation Function for Nearest Neighbors\n",
    "########################################\n",
    "# Can't use regression model because ids are categorical identifiers\n",
    "knn = neighbors.NearestNeighbors(n_neighbors=10, algorithm='ball_tree')\n",
    "all_track_ids_list = list(track_latent.keys())\n",
    "all_vectors = np.array(list(track_latent.values()))\n",
    "# knn.fit(all_vectors, all_track_ids_list)\n",
    "knn.fit(all_vectors)\n",
    "\n",
    "def recommend_nearest(target_track, track_latent = track_latent, top_n=10):\n",
    "    if target_track not in track_latent:\n",
    "        print(f\"Track {target_track} not found.\")\n",
    "        return []\n",
    "    target_vector = track_latent[target_track].reshape(1, -1)\n",
    "    distances, indices = knn.kneighbors(target_vector, n_neighbors=top_n)\n",
    "    recommendations = [(all_track_ids_list[idx], distances[0][j]) for j, idx in enumerate(indices[0])]\n",
    "    return recommendations[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74e656e8-4918-4c72-a529-aa2bfff5b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Part 7: Recommendation Function for GMM and Nearest Neighbors\n",
    "########################################\n",
    "gmm = GaussianMixture(n_components=10, covariance_type='full', random_state=42)\n",
    "all_track_ids_list = list(track_latent.keys())\n",
    "all_vectors = np.array(list(track_latent.values()))\n",
    "gmm.fit(all_vectors)\n",
    "\n",
    "def recommend_GMM_nearest(target_track, track_latent = track_latent, top_n=10):\n",
    "    if target_track not in track_latent:\n",
    "        print(f\"Track {target_track} not found.\")\n",
    "        return []\n",
    "    target_vector = track_latent[target_track].reshape(1, -1)\n",
    "    predicted_label = gmm.predict(target_vector)\n",
    "\n",
    "    cluster_indices = np.where(self.labels == predicted_label)[0]\n",
    "    cluster_data = self.X_pca[cluster_indices]\n",
    "\n",
    "    # using nearest neighbor search\n",
    "    nbrs = NearestNeighbors(n_neighbors=10, metric='euclidean')\n",
    "    nbrs.fit(cluster_data)\n",
    "    distances, indices = nbrs.kneighbors(data_pca)\n",
    "\n",
    "    recommendations = [(all_track_ids_list[idx], distances[0][j]) for j, idx in enumerate(indices[0])]\n",
    "    return recommendations[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb46f3e4-0749-4bfb-b9f2-c9e71f1222f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Part 7: Evaluation via Masking and Hit Rate Metrics\n",
    "########################################\n",
    "# Define ground truth: for each track, the nearest neighbor in the original loc_pca space\n",
    "def ground_truth_top(target_index):\n",
    "    target_vec = interaction_matrix[target_index].reshape(1, -1)\n",
    "    sims = np.dot(interaction_matrix, target_vec.T).flatten() # Using dot product to find the closest vector\n",
    "    sims[target_index] = -np.inf  # exclude the track itself\n",
    "    best_idx = np.argmax(sims) # argmax = Returns the indices of the maximum values along an axis\n",
    "    return all_track_ids[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7085caa5-a17d-4d8f-8446-197fd8f75a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Pure CF model hit rate on a sample of tracks\n",
    "sample_size = 1000\n",
    "num_tracks = len(all_track_ids)\n",
    "sample_indices = np.random.choice(num_tracks, sample_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "498d72aa-b37f-406a-b1df-b78b64b9fc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure CF Hit Rate (Top-10): 0.1560\n"
     ]
    }
   ],
   "source": [
    "hits_cf = 0\n",
    "for i in sample_indices:\n",
    "    gt = ground_truth_top(i)\n",
    "    target_id = all_track_ids[i]\n",
    "    recs_cf = [rec for rec, score in recommend_tracks_dot_with_scores(target_id, track_latent, top_n=10)]\n",
    "    # If ground truth top is in the top 10 recommended tracks, recognize it as a hit\n",
    "    if gt in recs_cf:\n",
    "        hits_cf += 1\n",
    "hit_rate_cf = hits_cf / sample_size\n",
    "print(f\"Pure CF Hit Rate (Top-10): {hit_rate_cf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adeda337-7244-48fb-bfb0-dbc189a3ff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid (α = 1.0, pure CF) Hit Rate (Top-10): 0.0830\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Hybrid model (without weighting, i.e., pure concatenation)\n",
    "hybrid_hit_rate = 0\n",
    "for i in sample_indices:\n",
    "    gt = ground_truth_top(i)\n",
    "    target_id = all_track_ids[i]\n",
    "    recs_hybrid = [rec for rec, score in recommend_hybrid(target_id, hybrid_dict, top_n=10)]\n",
    "    # If ground truth top is in the top 10 recommended tracks, recognize it as a hit\n",
    "    if gt in recs_hybrid:\n",
    "        hybrid_hit_rate += 1\n",
    "hybrid_hit_rate = hybrid_hit_rate / sample_size\n",
    "print(f\"Hybrid (α = 1.0, pure CF) Hit Rate (Top-10): {hybrid_hit_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46d8c641-36dd-429d-ae14-9e81e3fc3950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighboring Hit Rate (Top-10): 0.1930\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Nearest Neighboring\n",
    "hits_KNN = 0\n",
    "for i in sample_indices:\n",
    "    gt = ground_truth_top(i)\n",
    "    target_id = all_track_ids[i]\n",
    "    recs_KNN = [rec for rec, score in recommend_nearest(target_id, track_latent, top_n=10)]\n",
    "    # If ground truth top is in the top 10 recommended tracks, recognize it as a hit\n",
    "    if gt in recs_KNN:\n",
    "        hits_KNN += 1\n",
    "hit_rate_NNR = hits_KNN / sample_size\n",
    "print(f\"Nearest Neighboring Hit Rate (Top-10): {hit_rate_NNR:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0830880e-521f-4055-b097-37759f09eec5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=6oR7ZQ7h5HRrPFLrIfserZ.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m gt \u001b[38;5;241m=\u001b[39m ground_truth_top(i)\n\u001b[0;32m      5\u001b[0m target_id \u001b[38;5;241m=\u001b[39m all_track_ids[i]\n\u001b[1;32m----> 6\u001b[0m recs_GNN_NN \u001b[38;5;241m=\u001b[39m [rec \u001b[38;5;28;01mfor\u001b[39;00m rec, score \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrecommend_GMM_nearest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack_latent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# If ground truth top is in the top 10 recommended tracks, recognize it as a hit\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gt \u001b[38;5;129;01min\u001b[39;00m recs_GNN_NN:\n",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m, in \u001b[0;36mrecommend_GMM_nearest\u001b[1;34m(target_track, track_latent, top_n)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrack \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_track\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[1;32m---> 13\u001b[0m predicted_label \u001b[38;5;241m=\u001b[39m \u001b[43mgmm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_track\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m cluster_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m==\u001b[39m predicted_label)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     16\u001b[0m cluster_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_pca[cluster_indices]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SENG474\\lib\\site-packages\\sklearn\\mixture\\_base.py:383\u001b[0m, in \u001b[0;36mBaseMixture.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict the labels for the data samples in X using trained model.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m    Component labels.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 383\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimate_weighted_log_prob(X)\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SENG474\\lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SENG474\\lib\\site-packages\\sklearn\\utils\\validation.py:1070\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_2d:\n\u001b[0;32m   1068\u001b[0m     \u001b[38;5;66;03m# If input is scalar raise error\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1071\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got scalar array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1072\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1073\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1074\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1075\u001b[0m         )\n\u001b[0;32m   1076\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1078\u001b[0m         \u001b[38;5;66;03m# If input is a Series-like object (eg. pandas Series or polars Series)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=6oR7ZQ7h5HRrPFLrIfserZ.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Evaluate GMM Nearest Neighboring\n",
    "hits_GMM_NN = 0\n",
    "for i in sample_indices:\n",
    "    gt = ground_truth_top(i)\n",
    "    target_id = all_track_ids[i]\n",
    "    recs_GNN_NN = [rec for rec, score in recommend_GMM_nearest(target_id, track_latent, top_n=10)]\n",
    "    # If ground truth top is in the top 10 recommended tracks, recognize it as a hit\n",
    "    if gt in recs_GNN_NN:\n",
    "        hits_GNN_NN += 1\n",
    "hit_rate_GNN_NN = hits_GNN_NN / sample_size\n",
    "print(f\"Gausian Mixture Nearest Neighboring Hit Rate (Top-10): {hit_rate_GNN_NN:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6bf258-1092-4dd5-9023-139929b9c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Part 8: Grid Search for Weighted Hybrid Model\n",
    "########################################\n",
    "# We combine CF and content features using a weight: \n",
    "# Weighted Hybrid = [α × CF_latent, (1-α) × content_scaled]\n",
    "alphas = [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "hit_rates = []\n",
    "for alpha in alphas:\n",
    "    weighted_hybrid_vectors = np.concatenate([alpha * cf_latent, (1 - alpha) * content_scaled], axis=1)\n",
    "    weighted_hybrid_dict = {df.iloc[i][\"id\"]: weighted_hybrid_vectors[i] for i in range(len(df))}\n",
    "    hits = 0\n",
    "    for i in sample_indices:\n",
    "        gt = ground_truth_top(i)\n",
    "        target_id = all_track_ids[i]\n",
    "        recs = [rec for rec, score in recommend_hybrid(target_id, weighted_hybrid_dict, top_n=10)]\n",
    "        if gt in recs:\n",
    "            hits += 1\n",
    "    hit_rate = hits / sample_size\n",
    "    hit_rates.append(hit_rate)\n",
    "    print(f\"Alpha: {alpha:.1f} -> Hit Rate: {hit_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b348c-0b68-4bd7-9a79-d8c89ffbeeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Hit Rate vs. Alpha\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(alphas, hit_rates, marker='o', linestyle='-')\n",
    "plt.xlabel(\"Alpha (CF weight)\")\n",
    "plt.ylabel(\"Hit Rate (Top-10)\")\n",
    "plt.title(\"Hit Rate vs. Alpha for Weighted Hybrid Model\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f0f14-c6a5-4a0c-8794-51a4db05e262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
