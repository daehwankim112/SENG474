{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "84b44394-c2fb-4724-affa-cf07d8d8c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Part 1: Data Loading and Preprocessing\n",
    "########################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import neighbors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d2cc3a72-4933-4bd6-97f7-4289e84f05bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Example rows:\n",
      "                       id  danceability    energy       key  loudness  \\\n",
      "0  7lmeHLHBe4nmXzuXc0HDjk     -0.239643  1.545439  0.504262  0.855004   \n",
      "1  1wsRitfRRtWyEapl0q22o8      0.448997  1.470214  1.632828  0.794662   \n",
      "2  1hR0fIFK2qRG3f3RF70pb7     -1.067078  1.516782  0.504262  0.850871   \n",
      "3  2lbASgTSoDO7MTuLAXlTW0     -0.399791  1.506035  1.632828  0.783751   \n",
      "4  1MQTmpYOZ6fcMQc56Hdo7T     -0.474528  1.369913 -0.906446  0.635127   \n",
      "\n",
      "   speechiness  acousticness  instrumentalness  liveness   valence  ...  \\\n",
      "0    -0.084450     -1.018675         -0.663029  0.731281  0.184434  ...   \n",
      "1     0.998881     -1.054604         -0.662862 -0.286777  0.132294  ...   \n",
      "2     3.770628     -1.026024         -0.663054 -0.453920 -0.310892  ...   \n",
      "3     1.459273     -0.646043         -0.663049 -0.458985  0.448856  ...   \n",
      "4    -0.108879     -1.085308         -0.369701 -0.672220  0.318507  ...   \n",
      "\n",
      "   loc_pca_0  loc_pca_1  loc_pca_2  loc_pca_3  loc_pca_4  loc_pca_5  \\\n",
      "0  24.203403  -0.158920   0.247126   0.789665  -0.060023  -0.640468   \n",
      "1  28.493807   0.228536   0.646449   1.706311  -0.004733  -1.077771   \n",
      "2   4.036218  -0.282505   0.266417   0.224058  -0.022911  -1.097135   \n",
      "3   0.141121  -0.180057   0.039945  -0.117471   0.191789  -0.015862   \n",
      "4  11.897067  -0.646398   0.500255  -0.252342   0.111723  -0.587308   \n",
      "\n",
      "   loc_pca_6  loc_pca_7  loc_pca_8  loc_pca_9  \n",
      "0   1.330385  -0.857548  -0.423787   0.039703  \n",
      "1   0.702044  -1.451287   0.963210   0.337379  \n",
      "2  -0.075220  -0.147339   0.320747  -0.147518  \n",
      "3   0.012023  -0.025625   0.022630  -0.076836  \n",
      "4   0.765197  -0.737422  -0.186457  -0.062984  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data from new_features.csv\n",
    "df = pd.read_csv(\"../data/new_features.csv\")\n",
    "print(\"Data loaded. Example rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "99b898ce-a017-44f6-9f95-3a892a15cf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interaction matrix shape: (134712, 10)\n"
     ]
    }
   ],
   "source": [
    "# Extract the playlist location features (PCA-reduced), e.g., loc_pca_0 ... loc_pca_9\n",
    "loc_pca_cols = [col for col in df.columns if col.startswith(\"loc_pca_\")]\n",
    "interaction_matrix = df[loc_pca_cols].values\n",
    "print(\"\\nInteraction matrix shape:\", interaction_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "87feb08d-6d99-48e0-b0a2-90b2acf66b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF latent factors shape: (134712, 10)\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Part 2: Collaborative Filtering (CF) via SVD\n",
    "########################################\n",
    "# Apply Truncated SVD to the interaction matrix to obtain CF latent factors\n",
    "n_components = min(50, interaction_matrix.shape[1])\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "cf_latent = svd.fit_transform(interaction_matrix)\n",
    "print(\"CF latent factors shape:\", cf_latent.shape)\n",
    "\n",
    "# Map each track ID to its CF latent vector\n",
    "all_track_ids = df[\"id\"].values\n",
    "track_latent = {track_id: cf_latent[i] for i, track_id in enumerate(all_track_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "39be6658-3c0c-4b1e-bd9e-d18dcf36751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation function using dot product similarity (Pure CF)\n",
    "def recommend_tracks_dot_with_scores(target_track, track_latent, top_n=10):\n",
    "    if target_track not in track_latent:\n",
    "        print(f\"Track {target_track} not found.\")\n",
    "        return []\n",
    "    target_vector = track_latent[target_track]\n",
    "    all_track_ids_list = list(track_latent.keys())\n",
    "    all_vectors = np.array(list(track_latent.values()))\n",
    "    similarities = np.dot(all_vectors, target_vector)\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    recommendations = [(all_track_ids_list[i], similarities[i])\n",
    "                       for i in sorted_indices if all_track_ids_list[i] != target_track]\n",
    "    return recommendations[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b676a737-e1cd-4cf9-8154-6320d9917d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content features shape: (134712, 4)\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Part 3: Content-Based Feature Extraction\n",
    "########################################\n",
    "# Define audio feature columns; ensure popularity is present\n",
    "audio_cols = [\"danceability\", \"energy\", \"valence\", \"tempo\"]\n",
    "#if \"popularity\" not in df.columns:\n",
    "#    if \"occurrence_count\" in df.columns:\n",
    "#        df[\"popularity\"] = df[\"occurrence_count\"]\n",
    "#    else:\n",
    "#        df[\"popularity\"] = 1 # np.random.randint(100, 1000, size=len(df)) # Why? -David\n",
    "#content_cols = audio_cols + [\"popularity\"]\n",
    "\n",
    "# Standardize the content features\n",
    "scaler = StandardScaler()\n",
    "# content_scaled = scaler.fit_transform(df[content_cols].values)\n",
    "content_scaled = scaler.fit_transform(df[audio_cols].values)\n",
    "print(\"Content features shape:\", content_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ca25dc92-8cc8-400d-886c-c09ff3c98e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid vector shape: (134712, 14)\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Part 4: Hybrid Vector Construction\n",
    "########################################\n",
    "# Hybrid vector = [CF latent vector, Content features]\n",
    "hybrid_vectors = np.concatenate([cf_latent, content_scaled], axis=1) # cf_latent.shape = (134712, 10)\n",
    "print(\"Hybrid vector shape:\", hybrid_vectors.shape)\n",
    "# Build a discionary based on hybrid_vectors by id\n",
    "hybrid_dict = {df.iloc[i][\"id\"]: hybrid_vectors[i] for i in range(len(df))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "58b10235-5a3d-4497-87ea-774ca4f52a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Part 5: Recommendation Function for Hybrid Model\n",
    "########################################\n",
    "def recommend_hybrid(target_track, hybrid_dict, top_n=10):\n",
    "    if target_track not in hybrid_dict:\n",
    "        print(f\"Track {target_track} not found.\")\n",
    "        return []\n",
    "    target_vector = hybrid_dict[target_track]\n",
    "    all_ids = list(hybrid_dict.keys())\n",
    "    all_vectors = np.array(list(hybrid_dict.values()))\n",
    "    similarities = np.dot(all_vectors, target_vector) # Interesting. This works? - David\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    recommendations = [(all_ids[i], similarities[i])\n",
    "                       for i in sorted_indices if all_ids[i] != target_track]\n",
    "    return recommendations[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e2f735d0-9fc2-462d-a6e3-7545edf5409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Part 6: Recommendation Function for Nearest Neighbors Regrssion\n",
    "########################################\n",
    "# Can't use regression model because ids are categorical identifiers\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors=5, weights='uniform')\n",
    "all_track_ids_list = list(track_latent.keys())\n",
    "all_vectors = np.array(list(track_latent.values()))\n",
    "knn.fit(all_vectors, all_track_ids_list)\n",
    "\n",
    "def recommend_nearest(target_track, track_latent = track_latent, top_n=10):\n",
    "    if target_track not in track_latent:\n",
    "        print(f\"Track {target_track} not found.\")\n",
    "        return []\n",
    "    target_vector = track_latent[target_track].reshape(1, -1)\n",
    "    distances, indices = knn.kneighbors(target_vector, n_neighbors=top_n)\n",
    "    recommendations = [(all_track_ids_list[idx], distances[0][j]) for j, idx in enumerate(indices[0])]\n",
    "    return recommendations[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eb46f3e4-0749-4bfb-b9f2-c9e71f1222f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Part 6: Evaluation via Masking and Hit Rate Metrics\n",
    "########################################\n",
    "# Define ground truth: for each track, the nearest neighbor in the original loc_pca space\n",
    "def ground_truth_top(target_index):\n",
    "    target_vec = interaction_matrix[target_index].reshape(1, -1)\n",
    "    sims = np.dot(interaction_matrix, target_vec.T).flatten() # Using dot product to find the closest vector\n",
    "    sims[target_index] = -np.inf  # exclude the track itself\n",
    "    best_idx = np.argmax(sims) # argmax = Returns the indices of the maximum values along an axis\n",
    "    return all_track_ids[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7085caa5-a17d-4d8f-8446-197fd8f75a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Pure CF model hit rate on a sample of tracks\n",
    "sample_size = 1000\n",
    "num_tracks = len(all_track_ids)\n",
    "sample_indices = np.random.choice(num_tracks, sample_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "498d72aa-b37f-406a-b1df-b78b64b9fc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure CF Hit Rate (Top-10): 0.1520\n"
     ]
    }
   ],
   "source": [
    "hits_cf = 0\n",
    "for i in sample_indices:\n",
    "    gt = ground_truth_top(i)\n",
    "    target_id = all_track_ids[i]\n",
    "    recs_cf = [rec for rec, score in recommend_tracks_dot_with_scores(target_id, track_latent, top_n=10)]\n",
    "    # If ground truth top is in the top 10 recommended tracks, recognize it as a hit\n",
    "    if gt in recs_cf:\n",
    "        hits_cf += 1\n",
    "hit_rate_cf = hits_cf / sample_size\n",
    "print(f\"Pure CF Hit Rate (Top-10): {hit_rate_cf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "adeda337-7244-48fb-bfb0-dbc189a3ff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid (α = 1.0, pure CF) Hit Rate (Top-10): 0.0790\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Hybrid model (without weighting, i.e., pure concatenation)\n",
    "hybrid_hit_rate = 0\n",
    "for i in sample_indices:\n",
    "    gt = ground_truth_top(i)\n",
    "    target_id = all_track_ids[i]\n",
    "    recs_hybrid = [rec for rec, score in recommend_hybrid(target_id, hybrid_dict, top_n=10)]\n",
    "    # If ground truth top is in the top 10 recommended tracks, recognize it as a hit\n",
    "    if gt in recs_hybrid:\n",
    "        hybrid_hit_rate += 1\n",
    "hybrid_hit_rate = hybrid_hit_rate / sample_size\n",
    "print(f\"Hybrid (α = 1.0, pure CF) Hit Rate (Top-10): {hybrid_hit_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "46d8c641-36dd-429d-ae14-9e81e3fc3950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighboring Regression Hit Rate (Top-10): 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Nearest Neighboring Regression\n",
    "hits_NNR = 0\n",
    "for i in sample_indices:\n",
    "    gt = ground_truth_top(i)\n",
    "    target_id = all_track_ids[i]\n",
    "    recs_NNR = [rec for rec, score in recommend_nearest(target_id, track_latent, top_n=10)]\n",
    "    # If ground truth top is in the top 10 recommended tracks, recognize it as a hit\n",
    "    if gt is recs_NNR:\n",
    "        hits_NNR += 1\n",
    "hit_rate_NNR = hits_NNR / sample_size\n",
    "print(f\"Nearest Neighboring Regression Hit Rate (Top-10): {hit_rate_NNR:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6bf258-1092-4dd5-9023-139929b9c2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.6 -> Hit Rate: 0.0800\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Part 7: Grid Search for Weighted Hybrid Model\n",
    "########################################\n",
    "# We combine CF and content features using a weight: \n",
    "# Weighted Hybrid = [α × CF_latent, (1-α) × content_scaled]\n",
    "alphas = [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "hit_rates = []\n",
    "for alpha in alphas:\n",
    "    weighted_hybrid_vectors = np.concatenate([alpha * cf_latent, (1 - alpha) * content_scaled], axis=1)\n",
    "    weighted_hybrid_dict = {df.iloc[i][\"id\"]: weighted_hybrid_vectors[i] for i in range(len(df))}\n",
    "    hits = 0\n",
    "    for i in sample_indices:\n",
    "        gt = ground_truth_top(i)\n",
    "        target_id = all_track_ids[i]\n",
    "        recs = [rec for rec, score in recommend_hybrid(target_id, weighted_hybrid_dict, top_n=10)]\n",
    "        if gt in recs:\n",
    "            hits += 1\n",
    "    hit_rate = hits / sample_size\n",
    "    hit_rates.append(hit_rate)\n",
    "    print(f\"Alpha: {alpha:.1f} -> Hit Rate: {hit_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b348c-0b68-4bd7-9a79-d8c89ffbeeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Hit Rate vs. Alpha\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(alphas, hit_rates, marker='o', linestyle='-')\n",
    "plt.xlabel(\"Alpha (CF weight)\")\n",
    "plt.ylabel(\"Hit Rate (Top-10)\")\n",
    "plt.title(\"Hit Rate vs. Alpha for Weighted Hybrid Model\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f0f14-c6a5-4a0c-8794-51a4db05e262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
