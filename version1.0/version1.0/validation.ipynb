{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "199dfe2d-ec37-4e33-8875-0eaa9414dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189daa96-c3ff-4f64-9381-847e949ce703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                             id  danceability    energy       key  loudness  \\\n",
      "0       7lmeHLHBe4nmXzuXc0HDjk     -0.239643  1.545439  0.504262  0.855004   \n",
      "1       1wsRitfRRtWyEapl0q22o8      0.448997  1.470214  1.632828  0.794662   \n",
      "2       1hR0fIFK2qRG3f3RF70pb7     -1.067078  1.516782  0.504262  0.850871   \n",
      "3       2lbASgTSoDO7MTuLAXlTW0     -0.399791  1.506035  1.632828  0.783751   \n",
      "4       1MQTmpYOZ6fcMQc56Hdo7T     -0.474528  1.369913 -0.906446  0.635127   \n",
      "...                        ...           ...       ...       ...       ...   \n",
      "134707  0tOyrixMQ17NUznPIxYtVD      1.644775 -0.310129  1.068545  0.406157   \n",
      "134708  4mjGy5qFexa73Bwdo50dWk      1.132299  0.764524 -0.906446  0.664720   \n",
      "134709  4XQprvwbCyAb7k9ETF0Udn      0.219450 -0.825963 -0.906446 -0.372176   \n",
      "134710  63C7ypxBOdeUSAQsoulDoO     -0.522572  0.657059  1.350686  0.751679   \n",
      "134711  4GMAChvptmrvOS0pnP7oay      0.651852  1.011695  1.068545  1.087116   \n",
      "\n",
      "        speechiness  acousticness  instrumentalness  liveness   valence  \\\n",
      "0         -0.084450     -1.018675         -0.663029  0.731281  0.184434   \n",
      "1          0.998881     -1.054604         -0.662862 -0.286777  0.132294   \n",
      "2          3.770628     -1.026024         -0.663054 -0.453920 -0.310892   \n",
      "3          1.459273     -0.646043         -0.663049 -0.458985  0.448856   \n",
      "4         -0.108879     -1.085308         -0.369701 -0.672220  0.318507   \n",
      "...             ...           ...               ...       ...       ...   \n",
      "134707     0.303595      0.344739         -0.663054 -0.794286  0.255195   \n",
      "134708    -0.176528     -1.086424          1.625137  0.391928  0.951631   \n",
      "134709    -0.305250      0.919066         -0.661123 -0.595739 -1.025949   \n",
      "134710     1.252566     -0.074438         -0.663059 -0.773013  0.858524   \n",
      "134711    -0.414241     -1.085172         -0.663059  0.675566  1.156465   \n",
      "\n",
      "           tempo  occurrence_count  \n",
      "0      -0.028937          2.443088  \n",
      "1      -0.494485          2.876495  \n",
      "2       1.013129          0.407887  \n",
      "3      -0.721204          0.014031  \n",
      "4       0.270596          1.200544  \n",
      "...          ...               ...  \n",
      "134707  0.037462         -0.073310  \n",
      "134708  1.350263         -0.089789  \n",
      "134709  0.260516         -0.099677  \n",
      "134710 -1.227789         -0.099677  \n",
      "134711 -0.745585         -0.074958  \n",
      "\n",
      "[134712 rows x 12 columns]>\n"
     ]
    }
   ],
   "source": [
    "df_features = pd.read_csv('scaled_songs.csv')\n",
    "print(df_features.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be2acf81-75d1-4a57-9f19-648995989368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134712, 12)\n",
      "(134712, 11)\n"
     ]
    }
   ],
   "source": [
    "np_features = df_features.to_numpy() \n",
    "print(np_features.shape)\n",
    "np_features_copy = np_features[:,1:]\n",
    "print(np_features_copy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6570f9a-f1b2-4c6e-a36a-d650a1428918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1c6c9-d9fd-47d2-a5fd-116ca091aee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.96210933 -0.7600901   0.11397433  1.12737109  2.27210076]\n",
      " [-2.12941691  0.37746909  0.19882264  0.37648318  3.29836101]\n",
      " [-2.01111087 -0.93674442  1.79391519 -0.1993902   0.86890995]\n",
      " [-1.69670956  0.05878575  0.78746524 -1.25357575  1.06985496]\n",
      " [-1.46229385 -0.70737473 -0.90926728  1.36577121  0.47064951]]\n"
     ]
    }
   ],
   "source": [
    "# Using Pca to decrease the dimension\n",
    "pca = PCA(n_components=5)\n",
    "X_pca = pca.fit_transform(np_features_copy)\n",
    "print(X_pca[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2034fce5-d130-4fa5-83f2-ef3e4bc8aacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict label for every data point： [6 7 6 ... 9 4 4]\n",
      "The posterior probability of each data point is:\n",
      " [[3.99577985e-072 6.11277223e-223 2.73901774e-114 ... 2.07880365e-001\n",
      "  7.85052725e-077 2.69448140e-078]\n",
      " [1.79759221e-101 0.00000000e+000 1.55180060e-174 ... 6.25883197e-001\n",
      "  1.96375605e-107 1.41646460e-125]\n",
      " [9.30735636e-002 3.46994629e-057 7.36083578e-015 ... 6.57996991e-004\n",
      "  1.45037461e-003 1.92065482e-027]\n",
      " ...\n",
      " [4.94921033e-006 2.96076936e-002 2.09038649e-003 ... 1.31584566e-005\n",
      "  2.42045751e-005 9.50486589e-001]\n",
      " [3.93372301e-002 2.60012674e-023 3.26957742e-024 ... 1.86024171e-004\n",
      "  7.99883031e-003 6.44368567e-008]\n",
      " [3.34154675e-001 4.62661484e-024 5.02026440e-017 ... 1.42034594e-004\n",
      "  3.56364674e-003 2.27204912e-007]]\n"
     ]
    }
   ],
   "source": [
    "gmm = GaussianMixture(n_components=10, covariance_type='full', random_state=42)\n",
    "\n",
    "gmm.fit(X_pca)\n",
    "\n",
    "labels = gmm.predict(X_pca)\n",
    "\n",
    "probs = gmm.predict_proba(X_pca)\n",
    "\n",
    "print(\"Predict label for every data point:\", labels)\n",
    "print(\"The posterior probability of each data point is:\\n\", probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "961a4c8e-fdce-4b9e-9ac1-2d52e4af5d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134712\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbef508-5145-4fd6-a466-e9e645ddd7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      3524\n",
      "           1       0.95      0.95      0.95      3112\n",
      "           2       0.91      0.90      0.90      1957\n",
      "           3       0.92      0.91      0.92      2243\n",
      "           4       0.89      0.88      0.88      2391\n",
      "           5       0.92      0.91      0.92      4033\n",
      "           6       0.91      0.91      0.91       621\n",
      "           7       0.98      0.96      0.97       193\n",
      "           8       0.96      0.80      0.88       395\n",
      "           9       0.91      0.94      0.93      8474\n",
      "\n",
      "    accuracy                           0.92     26943\n",
      "   macro avg       0.93      0.91      0.92     26943\n",
      "weighted avg       0.92      0.92      0.92     26943\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3119    5    0    2  108   65    8    0    0  217]\n",
      " [   3 2950    0    5    0    5    0    0    0  149]\n",
      " [   0    0 1758   80    6   46    1    0    0   66]\n",
      " [   1    5   71 2047    1   19   19    0    0   80]\n",
      " [  86    0    4    0 2108   57    3    0    0  133]\n",
      " [  68   37   53   23   72 3688    0    0   11   81]\n",
      " [   5    1    2    4    1   19  566    4    1   18]\n",
      " [   0    0    0    0    0    0    7  186    0    0]\n",
      " [   0    0    7    0   17   54    0    0  317    0]\n",
      " [ 129  110   47   58   64   75   16    0    0 7975]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Assume np_features_copy is your original normalized data, labels is the pseudo-labels obtained by clustering\n",
    "\n",
    "# Divide the dataset: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(np_features_copy, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and train a random forest model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set results\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Output evaluation results\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fec6c4d-ff4f-4e2c-9f42-e2dcfdcbe822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      3524\n",
      "           1       0.95      0.98      0.97      3112\n",
      "           2       0.93      0.93      0.93      1957\n",
      "           3       0.94      0.94      0.94      2243\n",
      "           4       0.94      0.94      0.94      2391\n",
      "           5       0.96      0.95      0.96      4033\n",
      "           6       0.97      0.89      0.93       621\n",
      "           7       0.98      0.99      0.99       193\n",
      "           8       0.99      0.93      0.96       395\n",
      "           9       0.94      0.95      0.95      8474\n",
      "\n",
      "    accuracy                           0.95     26943\n",
      "   macro avg       0.96      0.94      0.95     26943\n",
      "weighted avg       0.95      0.95      0.95     26943\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3298    3    0    3   57   18    2    0    0  143]\n",
      " [   3 3046    0    4    0    2    0    0    0   57]\n",
      " [   0    0 1829   42    1   36    0    0    1   48]\n",
      " [   1    8   44 2105    0   11    5    0    0   69]\n",
      " [  22    0    5    0 2240   23    0    0    2   99]\n",
      " [  26   54   29   12   30 3818    0    0    1   63]\n",
      " [   5    0    4   11    5   14  552    3    0   27]\n",
      " [   0    0    0    0    0    0    1  192    0    0]\n",
      " [   0    0    1    0   10   15    0    0  369    0]\n",
      " [ 120   89   62   58   38   22   12    0    0 8073]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Build and train the SVM model (the RBF kernel function is used here, and the kernel function and parameters can be adjusted according to the data)\n",
    "svm_clf = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set results\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "\n",
    "# Output evaluation results\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f2daa79-ac34-45e1-a4ce-9a70f23077eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data: [-1.067078059953224 1.5167818407892877 0.5042616931496741\n",
      " 0.8508713851510616 3.770628025370261 -1.0260241288695873\n",
      " -0.6630537914880389 -0.4539203864778992 -0.310891973773382\n",
      " 1.0131286944249982 0.4078874580558583]\n",
      "predicted_label is: 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# pick one from dataset\n",
    "new_data = np_features_copy[2,:]\n",
    "print('input data:',new_data)\n",
    "new_data = new_data.reshape(1, -1)\n",
    "\n",
    "# using PCA to decrease dimension\n",
    "new_data_pca = pca.transform(new_data)\n",
    "predicted_label = gmm.predict(new_data_pca)[0]\n",
    "print('predicted_label is:', predicted_label)\n",
    "\n",
    "# select all data belong to this labels\n",
    "cluster_indices = np.where(labels == predicted_label)[0]\n",
    "cluster_data = X_pca[cluster_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2524971f-5d9a-4644-bd05-ad84991a083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using nearest neighbor search\n",
    "nbrs = NearestNeighbors(n_neighbors=10, metric='euclidean')\n",
    "nbrs.fit(cluster_data)\n",
    "distances, local_indices = nbrs.kneighbors(new_data_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67f6a65d-8f0c-4879-b460-5a16daf6d707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended indices: [     2  90574  11710  79843  64898  86477  87519 128226 123664  64899]\n",
      "Corresponding distances: [[3.74874971e-13 2.61721940e-01 4.91084217e-01 7.81120559e-01\n",
      "  8.52213984e-01 8.73760681e-01 8.92696023e-01 9.25220217e-01\n",
      "  9.29999141e-01 9.48203163e-01]]\n"
     ]
    }
   ],
   "source": [
    "recommended_indices = cluster_indices[local_indices[0]]\n",
    "print(\"Recommended indices:\", recommended_indices)\n",
    "print(\"Corresponding distances:\", distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56848ca-e5b0-44fc-9278-2e2fe050a118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_pca 已保存为 X_pca.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assume X_pca is your dimensionally reduced data, with a shape of (n_samples, 5)\n",
    "# Specify column names for each principal component (can be adjusted based on actual conditions)\n",
    "columns = [\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\"]\n",
    "\n",
    "# create DataFrame\n",
    "df_pca = pd.DataFrame(X_pca, columns=columns)\n",
    "\n",
    "# Save as CSV file without saving row index\n",
    "df_pca.to_csv(\"X_pca.csv\", index=False)\n",
    "\n",
    "print(\"X_pca already save as X_pca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99955cd4-e70a-4a8a-855a-c1d71f82734d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels 已保存为 labels.csv\n"
     ]
    }
   ],
   "source": [
    "columns = [\"label\"]\n",
    "\n",
    "# create DataFrame\n",
    "df_pca = pd.DataFrame(labels, columns=columns)\n",
    "\n",
    "# Save as CSV file without saving row index\n",
    "df_pca.to_csv(\"labels.csv\", index=False)\n",
    "\n",
    "print(\"labels was saved as labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ceca55-6517-48e2-9f84-cbca76f65c04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
